{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff9f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\20ngu\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\20ngu\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\20ngu\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\20ngu\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\20ngu\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\20ngu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59436d2e",
   "metadata": {},
   "source": [
    "# Prepare Bloom CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ade88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "def ParseRawBloomData(file, cities):\n",
    "    # Open and read the contents of the page\n",
    "    with open(file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    header = [colheader.strip() for colheader in lines[0].strip().split()]\n",
    "    \n",
    "    # Initialize a dictionary to store the data\n",
    "    data = {}    \n",
    "\n",
    "    for line in lines[1:]:\n",
    "        words = [word.strip() for word in line.strip().split()]\n",
    "\n",
    "        # Only includes the data of the specified cities\n",
    "        if words[0] not in cities:\n",
    "            continue\n",
    "        if words[0] not in data:\n",
    "            data[words[0]] = {}\n",
    "\n",
    "        column = 1\n",
    "        month = 0\n",
    "        day = 0\n",
    "\n",
    "        # Adds data to the dictionary\n",
    "        for i in range(1, len(words), 1):\n",
    "            word = words[i]\n",
    "\n",
    "            # Once reaches these columns, finish\n",
    "            if header[column].lower() == \"normal_value\" or header[column].lower() == \"alternative_event\":\n",
    "                break\n",
    "\n",
    "            # Parses data into the columns\n",
    "            if word == \"-\":\n",
    "                column = column + 1 \n",
    "            elif word.isdigit():\n",
    "                if month == 0:\n",
    "                    month = int(word)\n",
    "                    continue\n",
    "                else:\n",
    "                    day = int(word)\n",
    "\n",
    "                # Converts month-day pair to day-of-year    \n",
    "                data[words[0]][header[column]] = date(int(header[column]), month, day).timetuple().tm_yday\n",
    "\n",
    "                month = 0\n",
    "                day = 0\n",
    "                column = column + 1\n",
    "    \n",
    "    return data           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a806b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  ...  \\\n",
      "Sapporo     129   125   125   128   136   131   124   125   130   129  ...   \n",
      "Sendai      106   111   108   110   115   108   108   105   110   115  ...   \n",
      "Nagoya       96   102    96    98   106    93    95    96    97   102  ...   \n",
      "Tokyo        98    99    96    96   102    95    95    94   100   105  ...   \n",
      "Kyoto        96    97    99    97   107    96    96    96   103   105  ...   \n",
      "Hiroshima    96   102    98    97   107    97    98    98   103   104  ...   \n",
      "Osaka        95    99   103   106    95    93    94   101   104    94  ...   \n",
      "Matsuyama    95   101   105    95   100    95    93    95   101   102  ...   \n",
      "Fukuoka      93    98    97    95    98    94    94    94    97    98  ...   \n",
      "\n",
      "           2013  2014  2015  2016  2017  2018  2019  2020  2021  2022  \n",
      "Sapporo     137   121   116   122   123   119   119   123   117   115  \n",
      "Sendai      105   101    99    97   103    94   100    94    90   101  \n",
      "Nagoya       87    90    89    91    96    86    94    92    87    89  \n",
      "Tokyo        81    89    88    91    92    83    86    82    81    86  \n",
      "Kyoto        89    92    91    93    97    87    96    90    85    89  \n",
      "Hiroshima    88    89    89    93    97    87    93    94    84    88  \n",
      "Osaka        88    92    91    92    96    85    94    94    87    89  \n",
      "Matsuyama    86    88    91    94    98    86    95   100    86    87  \n",
      "Fukuoka      81    86    88    90    95    86    88    93    81    86  \n",
      "\n",
      "[9 rows x 62 columns]\n",
      "           1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  ...  \\\n",
      "Sapporo     124   120   122   125   133   123   121   117   125   123  ...   \n",
      "Sendai      101   104   102   102   110   101   101   101   104   111  ...   \n",
      "Nagoya       90    93    92    93    98    83    88    93    91    97  ...   \n",
      "Tokyo        91    91    91    93    92    79    89    89    96    97  ...   \n",
      "Kyoto        90    92    94    96    99    86    91    93    97    99  ...   \n",
      "Hiroshima    90    89    92    93    92    85    88    93    95    96  ...   \n",
      "Osaka        92    94    92    94   100    82    89    92    97    98  ...   \n",
      "Matsuyama    88    91    91    93    93    83    87    91    93    92  ...   \n",
      "Fukuoka      87    96    93    92    89    79    87    91    94    93  ...   \n",
      "\n",
      "           2013  2014  2015  2016  2017  2018  2019  2020  2021  2022  \n",
      "Sapporo     133   119   112   116   118   116   114   121   112   113  \n",
      "Sendai       99    97    93    92    97    89    95    88    87    98  \n",
      "Nagoya       78    83    80    79    87    78    81    82    76    81  \n",
      "Tokyo        75    84    82    81    80    76    80    74    73    79  \n",
      "Kyoto        81    86    86    83    90    81    86    82    75    83  \n",
      "Hiroshima    81    84    83    83    86    81    81    82    70    80  \n",
      "Osaka        80    86    85    83    89    79    86    83    78    82  \n",
      "Matsuyama    76    83    86    83    89    78    81    85    74    80  \n",
      "Fukuoka      72    78    81    79    84    78    80    81    71    76  \n",
      "\n",
      "[9 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "def PrepareBloomCSVFile(rawdatafiles, whitelistedCities, filename):\n",
    "\n",
    "    # Parses all the data points together from the files\n",
    "    totalData = []\n",
    "    for file in rawdatafiles:\n",
    "        partData = ParseRawBloomData(\"raw_data/\" + file, whitelistedCities)\n",
    "        # Transpose so that the columns would contain the years, and rows the cities\n",
    "        dataframe = pd.DataFrame.from_dict(partData).fillna(-1).astype(int).T\n",
    "        totalData.append(dataframe)\n",
    "\n",
    "\n",
    "    # Create a DataFrame from the parsed data\n",
    "    # Concatentates based on the horizontal axis (column based), since years are part of the columns\n",
    "    output = pd.concat(totalData, axis=1)\n",
    "    output.to_csv(filename)\n",
    "    print(output)\n",
    "\n",
    "    \n",
    "def PrepareBloomFiles():\n",
    "    # Define the list of cities to include in the csv\n",
    "    whitelistedCities = [\"Sapporo\", \"Sendai\", \"Tokyo\", \"Nagoya\", \"Osaka\", \"Kyoto\", \"Hiroshima\", \"Matsuyama\", \"Fukuoka\"]\n",
    "    \n",
    "    # Defines raw data files to parse and concatenate\n",
    "    # Sourced from: https://www.data.jma.go.jp/sakura/data/sakura004_01.html\n",
    "    rawdatafiles1 = [\"rawdata_full_bloom_1961_1970.txt\", \"rawdata_full_bloom_1971_1980.txt\", \n",
    "                     \"rawdata_full_bloom_1981_1990.txt\", \"rawdata_full_bloom_1991_2000.txt\", \n",
    "                     \"rawdata_full_bloom_2001_2010.txt\", \"rawdata_full_bloom_2011_2020.txt\", \n",
    "                     \"rawdata_full_bloom_2021_2022.txt\"]\n",
    "    # Sourced from: https://www.data.jma.go.jp/sakura/data/sakura003_01.html\n",
    "    rawdatafiles2 = [\"rawdata_bloom_1961_1970.txt\", \"rawdata_bloom_1971_1980.txt\", \n",
    "                     \"rawdata_bloom_1981_1990.txt\", \"rawdata_bloom_1991_2000.txt\", \n",
    "                     \"rawdata_bloom_2001_2010.txt\", \"rawdata_bloom_2011_2020.txt\", \n",
    "                     \"rawdata_bloom_2021_2022.txt\"]\n",
    "    # Note: Missing bloom day values should be manually estimated based on other cities' bloom days in similar geographic location.\n",
    "    \n",
    "    PrepareBloomCSVFile(rawdatafiles1, whitelistedCities, \"full_bloom_data.csv\")\n",
    "    PrepareBloomCSVFile(rawdatafiles2, whitelistedCities, \"bloom_data.csv\")\n",
    "\n",
    "    \n",
    "PrepareBloomFiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213441e",
   "metadata": {},
   "source": [
    "# Prepare City Temperatures CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a996478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import chardet # Used to determine the encoding scheme of a given file\n",
    "\n",
    "\n",
    "def StripAndConcatCityTemperatureCSVs(city, fileParts):\n",
    "    directory = \"temperatures_data/\" + city.lower()\n",
    "    if not os.path.exists(directory):\n",
    "        raise Exception(\"Dependent city directory is missing.\")\n",
    "    \n",
    "    # Processes temperature data together from the files\n",
    "    totalData = []\n",
    "    for fileName in fileParts:\n",
    "        directory = \"temperatures_data/\" + city.lower() + \"/\" + fileName\n",
    "        \n",
    "        # Open and prepares the contents of the csv, ignoring the first 5 rows\n",
    "        dataframe = pd.read_csv(directory, skiprows=4, encoding=\"SHIFT_JIS\")\n",
    "        \n",
    "        # Creates new heading and removes unnecessary columns\n",
    "        dataframe = dataframe.iloc[:, :-2]\n",
    "        dataframe.columns = [\"year\", \"temperature\"]\n",
    "\n",
    "        # Adds day-of-year column and truncates year column\n",
    "        dataframe.insert(loc=1, column=\"day\", value=dataframe[\"year\"])\n",
    "        dataframe[\"day\"] = dataframe[\"day\"].apply(lambda x: datetime.strptime(x, '%Y/%m/%d').timetuple().tm_yday)\n",
    "        dataframe[\"year\"] = dataframe[\"year\"].apply(lambda x: x[:4])\n",
    "        \n",
    "        totalData.append(dataframe)\n",
    "        \n",
    "    # Concatentates based on the vertical axis (row based)  \n",
    "    output = pd.concat(totalData, axis=0)\n",
    "    output = output.fillna(method=\"bfill\")\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def AddFeaturesToDataFrame(dataframe):\n",
    "    dataframe.loc[:,\"week_mean\"] = dataframe.loc[:,\"temperature\"].rolling(window=7, min_periods=1).mean()\n",
    "    dataframe.loc[:,\"2week_mean\"] = dataframe.loc[:,\"temperature\"].rolling(window=14, min_periods=1).mean()\n",
    "    dataframe.loc[:,\"4week_mean\"] = dataframe.loc[:,\"temperature\"].rolling(window=28, min_periods=1).mean()\n",
    "    dataframe.loc[:,\"8week_mean\"] = dataframe.loc[:,\"temperature\"].rolling(window=56, min_periods=1).mean()\n",
    "    dataframe.loc[:,\"16week_mean\"] = dataframe.loc[:,\"temperature\"].rolling(window=112, min_periods=1).mean()\n",
    "    \n",
    "    # Total Temperature Accumulation\n",
    "    dataframe['sum'] = pd.Series(dtype=float)\n",
    "    accum = 0\n",
    "    for i in range(len(dataframe)):\n",
    "        if dataframe.iloc[i, dataframe.columns.get_loc(\"day\")] == 1:\n",
    "            accum = 0\n",
    "        accum = accum + dataframe.iloc[i, dataframe.columns.get_loc(\"temperature\")]\n",
    "        dataframe.iloc[i, dataframe.columns.get_loc(\"sum\")] = accum\n",
    "        \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def AddTargetToDataFrame(city, dataframe, targetfilename, targetname):\n",
    "    if not os.path.exists(targetfilename):\n",
    "        raise Exception(\"Dependent \"+ targetfilename +\" is missing.\")\n",
    "        \n",
    "    # Adds bloom status\n",
    "    dataframe[targetname] = np.zeros(len(dataframe), dtype=int)\n",
    "    targetbloom = pd.read_csv(targetfilename, index_col=False)\n",
    "    row = targetbloom.loc[targetbloom[\"Unnamed: 0\"] == city].drop(targetbloom.columns[0], axis=1)\n",
    "    \n",
    "    # How many days left until the bloom day. Negative values after the bloom day (Regression)\n",
    "    runningBloomDay = 0\n",
    "    for i in range(len(dataframe)):\n",
    "        day = dataframe.iloc[i, dataframe.columns.get_loc(\"day\")]\n",
    "        if day == 1:\n",
    "            runningBloomDay = row[str(dataframe.iloc[i, dataframe.columns.get_loc(\"year\")])]\n",
    "        dataframe.iloc[i, dataframe.columns.get_loc(targetname)] = runningBloomDay - day\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0785fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  day  temperature  bloom  full_bloom  week_mean  2week_mean  \\\n",
      "0    1961    1         -6.9    123         128  -6.900000   -6.900000   \n",
      "1    1961    2         -7.0    122         127  -6.950000   -6.950000   \n",
      "2    1961    3         -3.0    121         126  -5.633333   -5.633333   \n",
      "3    1961    4         -3.2    120         125  -5.025000   -5.025000   \n",
      "4    1961    5         -6.6    119         124  -5.340000   -5.340000   \n",
      "..    ...  ...          ...    ...         ...        ...         ...   \n",
      "725  2022  361          1.5   -248        -246   1.000000   -1.907143   \n",
      "726  2022  362          0.8   -249        -247   1.400000   -1.585714   \n",
      "727  2022  363         -2.3   -250        -248   1.171429   -1.392857   \n",
      "728  2022  364         -1.8   -251        -249   0.800000   -1.164286   \n",
      "729  2022  365          0.3   -252        -250   0.471429   -0.892857   \n",
      "\n",
      "     4week_mean  8week_mean  16week_mean  accumulated  \n",
      "0     -6.900000   -6.900000    -6.900000         -6.9  \n",
      "1     -6.950000   -6.950000    -6.950000        -13.9  \n",
      "2     -5.633333   -5.633333    -5.633333        -16.9  \n",
      "3     -5.025000   -5.025000    -5.025000        -20.1  \n",
      "4     -5.340000   -5.340000    -5.340000        -26.7  \n",
      "..          ...         ...          ...          ...  \n",
      "725   -1.378571    2.876786     9.214286       3734.3  \n",
      "726   -1.360714    2.700000     9.003571       3735.1  \n",
      "727   -1.275000    2.519643     8.792857       3732.8  \n",
      "728   -1.214286    2.375000     8.583036       3731.0  \n",
      "729   -1.217857    2.269643     8.406250       3731.3  \n",
      "\n",
      "[22645 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "def PrepareHistoricCityTemperaturesCSVFile(cityselect):\n",
    "    # Defines csv temperature data from the Japan's Meteorlogical Agency \n",
    "    # Sourced from: https://www.data.jma.go.jp/gmd/risk/obsdl/index.php\n",
    "    historyFileParts = [\"temperature_data_1961_1990.csv\", \"temperature_data_1991_2020.csv\", \"temperature_data_2021_2022.csv\"]\n",
    "    recentFileParts = [\"temperature_data_2021_2022.csv\", \"temperature_data_2023_present.csv\"]\n",
    "    \n",
    "    # Define the list of cities prepare\n",
    "    # Here for documentation purposes\n",
    "    whitelistedCities = [\"Sapporo\", \"Sendai\", \"Tokyo\", \"Nagoya\", \"Osaka\", \"Kyoto\", \"Hiroshima\", \"Matsuyama\", \"Fukuoka\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Creates history dataframe and csv\n",
    "    dataframe = StripAndConcatCityTemperatureCSVs(cityselect, historyFileParts)\n",
    "    dataframe = AddTargetToDataFrame(cityselect, dataframe, \"bloom_data.csv\", \"bloom\")\n",
    "    dataframe = AddTargetToDataFrame(cityselect, dataframe, \"full_bloom_data.csv\", \"full_bloom\")\n",
    "    dataframe = AddFeaturesToDataFrame(dataframe)\n",
    "    # dataframe = dataframe[dataframe['year'] != \"1961\"]\n",
    "    dataframe.to_csv(\"historic.csv\", index=False)\n",
    "    print(dataframe)\n",
    "    \n",
    "    # Creates csv for the current data used for prediction\n",
    "    predict = StripAndConcatCityTemperatureCSVs(cityselect, recentFileParts)\n",
    "    predict = AddFeaturesToDataFrame(predict)\n",
    "    # predict.to_csv(\"predict.csv\", index=False)\n",
    "    filteredPredict = predict[predict['year'] == \"2023\"]\n",
    "    filteredPredict.to_csv(\"predict.csv\", index=False)\n",
    "\n",
    "    \n",
    "PrepareHistoricCityTemperaturesCSVFile(\"Sapporo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649ae37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreparePredictCityTemperaturesCSVFile(cityselect):\n",
    "    # Defines csv temperature data from the Japan's Meteorlogical Agency \n",
    "    # Sourced from: https://www.data.jma.go.jp/gmd/risk/obsdl/index.php\n",
    "    recentFileParts = [\"temperature_data_2021_2022.csv\", \"temperature_data_2023_present.csv\"]\n",
    "    \n",
    "    # Define the list of cities prepare\n",
    "    # Here for documentation purposes\n",
    "    whitelistedCities = [\"Sapporo\", \"Sendai\", \"Tokyo\", \"Nagoya\", \"Osaka\", \"Kyoto\", \"Hiroshima\", \"Matsuyama\", \"Fukuoka\"]\n",
    "\n",
    "    \n",
    "    # Creates csv for the current data used for prediction\n",
    "    predict = StripAndConcatCityTemperatureCSVs(cityselect, recentFileParts)\n",
    "    predict = AddFeaturesToDataFrame(predict)\n",
    "    # predict.to_csv(\"predict.csv\", index=False)\n",
    "    filteredPredict = predict[predict['year'] == \"2023\"]\n",
    "    filteredPredict.to_csv(\"predict.csv\", index=False)\n",
    "\n",
    "    \n",
    "PreparePredictCityTemperaturesCSVFile(\"Sapporo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
